---
title: "Alsea Watershed 2016 Mean"
output: html_notebook
---

This set of R scripts processes logger data for predictive stream temperature modeling
Created: 27 Jun 2019
Updated: 28 Jun 2019
USGS station: 14306500

Stage setting:
```{r, message=FALSE}
library(timeSeries)
library(lattice)
library(foreign)
library(doBy)
library(qpcR)
library(pls)
library(boot)
library(Hmisc)
library(readxl)
library(lubridate)
library(zoo)
library(car)
library(gvlma)
library(ggplot2)
library(rgdal)
library(raster)
library(RColorBrewer)
library(classInt)
library(uuid)
```
```{r}
  basin <- "AL"
  midBasin <- "Alsea"
  longBasin <- "Alsea"
  yrPath <- "16"
  yearPath <- "2016"
  
  nameBasin <- "Alsea" #this is from the Projects XML list of approved names
  
  
  mainPath <- "D:/OneDrive/work/research/CHaMP/CHaMP_data/"
  metricPath <- "D:/OneDrive/work/research/CHaMP/CHaMP_data/Alsea/2016/metrics"
  
  var <- "Mn"
  longVar <- "Mean"
  dataVar <- "Mn8D" #name of the variable in the logger data
  capVar <- "MEAN"
  
  modelPath <- paste0(mainPath, midBasin, "/", yearPath, "/", longVar, "/")
  gisPath <- "D:/OneDrive/work/research/CHaMP/GIS/coverages/"
  
```

This part reads the LST data and gap-fills using a cubic spline function
```{r, message=FALSE}

  LST.in <- read.csv("D:/OneDrive/work/research/CHaMP/GIS/coverages/Alsea/Alsea_LST_2016.csv")
  PointID <- LST.in[,1]
  LST.in <- LST.in[,2:47]
  LST.in[LST.in<0.1] = NA
  
  LST.names<-colnames(LST.in)
  
  myFunc <- function(x)
    {
      if (is.na(x[1]))
      {
        x[1] <- 13022
      }
      x
    }
  
  LST.filled <- apply(LST.in, 1, function(x) myFunc(x))
  LST.filled <- as.data.frame(t(LST.filled))
  
  
  myFunc2 <- function(x)
    {
      if (is.na(x[46]))
      {
        x[46] <- x[43]
      }
      x
    }
  
  
  LST.filled <- apply(LST.filled, 1, function(x) myFunc2(x))
  LST.filled <- as.data.frame(t(LST.filled))
  
  myFunc3 <- function(x)
    {
      if (is.na(x[46]))
      {
        x[46] <- 12943
      }
      x
    }
  
  LST.filled <- apply(LST.filled, 1, function(x) myFunc3(x))
  LST.filled <- as.data.frame(t(LST.filled))
  
  tLST.in <- t(LST.filled)
  
  tLST.out <- na.spline(tLST.in)
  CLST <- tLST.out*0.2-273.15
  tCLST <- t(CLST)
  CLST.out <- as.data.frame(tCLST)
  
    
  CLST.out$PointID <- PointID
  colnames(CLST.out)[1:46] <- LST.names
```
Plot to look
```{r}
  plot(1:46, CLST.out[1,1:46])
  plot(1:46, CLST.out[1000,1:46])
```
```{r}
  
  write.dbf(CLST.out, file = paste0("D:/OneDrive/work/research/CHaMP/CHaMP_data/Alsea/2016/LST16_AL_interp.dbf"))
  
  
```
This part calculates the zonal mean of the daily LST for each RCA
```{r}
out_Preds <- read.dbf("D:/OneDrive/work/research/CHaMP/CHaMP_data/Alsea/2016/LST16_AL_interp.dbf")
  
  
  weights <- read.csv("D:/OneDrive/work/research/CHaMP/CHaMP_data/Alsea/AL_rca_area_wgts.csv")
  weights[weights$area_wgt<0.01, "area_wgt"] = 0.01
  colnames(weights)[1] <- "RCAID"
  rcas <- unique(unlist(weights$RCAID))
  rca_zonal <- matrix(ncol=46, nrow=length(rcas))
  
  
  l <- 1
  
  for(i in rcas)	
    {
      pixels <- weights[weights$RCAID == i, "PointID"]
      wgts <- weights[weights$RCAID == i, "area_wgt"]
      
      for (j in 1:46)
      {
        daily <- out_Preds[out_Preds$PointID %in% pixels, j]
        zonal_mn <- weighted.mean(daily, wgts, na.rm = TRUE)
        rca_zonal[l,j] <- zonal_mn
      }
      l <- l+1
    }
  
  
  colnames(rca_zonal)[1:46] <- colnames(out_Preds)[1:46]
  rca_zonal <- as.data.frame(rca_zonal)
  rca_zonal$RCAID <- rcas
```
Plot to look
```{r}
  plot(1:46, rca_zonal[1,1:46])
  plot(1:46, rca_zonal[100,1:46])
    write.dbf(rca_zonal, file = paste0("D:/OneDrive/work/research/CHaMP/CHaMP_data/Alsea/2016/LST16_AL_RCA.dbf"))
  
```
Discharge data formatting
```{r}

  Dv.in <- read.csv("D:/OneDrive/work/research/CHaMP/CHaMP_data/Alsea/2016/AL_dv_data_2016.csv", stringsAsFactors = FALSE)
  
  dates <- matrix(nrow=365, ncol=1)
  dates[,1] <- 1:365
  colnames(dates) <- c("Days")
  
  SiteID <- unique(Dv.in$site_no)
  SiteID <- as.matrix(SiteID)
  Dv.8Day.out <- data.frame (mup = NULL)
  
  for (i in SiteID) 
    { 
      Dv.site <- Dv.in[Dv.in$site_no == i,]
      full.year <- merge(dates, Dv.site, by.x = "Days", by.y = "JulDay", all.x = TRUE)
      eightday <- rollapply(full.year$Dv, width = 8, FUN = mean, na.rm = T, fill = NA, align = c("left"))
      eightday <- as.matrix(eightday)
      full.year$Dv8D<- eightday
      full.year$Dv8D[361] <- mean(full.year$Dv[361:365 ])
      Dv.8Day.out <- rbind(Dv.8Day.out, full.year)
      
    }
  
  ind <- apply(Dv.8Day.out, 1, function(x) !any(is.na(x)))
  Dv.8Day.out <- Dv.8Day.out[ind,]

write.csv(Dv.8Day.out, paste0("D:/OneDrive/work/research/CHaMP/CHaMP_data/Alsea/2016/AL_2016_Dv_8Day", ".csv"), row.names = FALSE)

```
Model building. Builds complete (no NA) dataset with discharge, elevation, LST, JulDay.  Splits data into spring and fall with the max temp of the year.
```{r}
  Log.in <- read.csv("D:/OneDrive/work/research/CHaMP/CHaMP_data/Alsea/2016/AL_logger_8D_2016.csv", stringsAsFactors = FALSE)
 

  ID.in <- read.csv("D:/OneDrive/work/research/CHaMP/GIS/coverages/Alsea/AL_sites_rca_2016.csv", stringsAsFactors = FALSE) 
  
  LST.in <- read.dbf(paste0("D:/OneDrive/work/research/CHaMP/CHaMP_data/Alsea/2016/LST16_AL_RCA.dbf"))
  colnames(LST.in)<-gsub("X", "", colnames(LST.in))
  newnamesnum <- as.numeric(colnames(LST.in)[1:46]);
  Dv.in <- read.csv("D:/OneDrive/work/research/CHaMP/CHaMP_data/Alsea/2016/AL_2016_Dv_8Day.csv", stringsAsFactors = FALSE)
  
  Dv.in <- Dv.in[,c("Dv8D", "Days")]
  
  LST.Log.out <- data.frame (mup = NULL)
  SiteID <- unique(Log.in$SiteName)
  
  for (i in SiteID) 
    { 
      Log.site <- Log.in[Log.in$SiteName  == i,]
      Log.site <- as.data.frame(Log.site)
      
      RCAID <- ID.in$RCAID[ID.in$SiteName == i]
      
      Elev <- ID.in$Elev[ID.in$SiteName == i]
      
      LST.site <- matrix(ncol=3, nrow=46)
      LST.site[,1] <- as.numeric(unlist(colnames(LST.in)[1:46]))
      LST.site[,2] <- unlist(LST.in[LST.in$RCAID == RCAID, 1:46])
      LST.site <- data.frame(LST.site)
      colnames(LST.site) <- c("JulDay", "LST", "Elev")
      LST.site[3] <- Elev
      LST.Log.site <- merge(LST.site, Log.site, by = "JulDay", all.x=TRUE, all.y = FALSE)
      LST.Log.site <- merge(LST.Log.site, Dv.in, by.x = "JulDay", by.y = "Days", all.x=TRUE, all.y+FALSE)
      
      LST.Log.out <- rbind(LST.Log.out, LST.Log.site)
      
    }
  
  
  Dv <- unlist(LST.Log.site$Dv8D)
 
  ind <- apply(LST.Log.out, 1, function(x) !any(is.na(x)))
  NoNA.xyz <- LST.Log.out[ind,]
  
  NoNA.xyz <- NoNA.xyz[,c(dataVar, "LST", "JulDay", "Elev", "Dv8D", "SiteName")]
  colnames(NoNA.xyz) <- c("y", "x", "z", "e", "d", "SiteName")
  
  write.csv(x=NoNA.xyz, file= paste0(basin, "_", yearPath, "_8Day_", var, "_model_data.csv"), row.names = FALSE)
  NoNA.xyz <- read.csv(paste0(basin, "_", yearPath, "_8Day_", var, "_model_data.csv"), stringsAsFactors = FALSE)
  
  NoNA.xyz <- orderBy(~z, NoNA.xyz)
  maxrow <- which.max(NoNA.xyz$y)
  data.sp <- NoNA.xyz[1:(maxrow-1),]
  rownames(data.sp) <- 1:dim(data.sp)[1]
  data.fall <- NoNA.xyz[maxrow:nrow(NoNA.xyz),]
  rownames(data.fall) <- 1:dim(data.fall)[1]
```
Correlation matrix
```{r}
cor.full <- NoNA.xyz[1:5]
cor(cor.full)
```
plot the data
```{r}
  {plot(NoNA.xyz$x, NoNA.xyz$y, main = "full year")
  points(data.sp$x, data.sp$y, pch=16, col="cadetblue3")
  points(data.fall$x, data.fall$y, pch=16, col="chocolate")}
  
```

####Full year models
```{r}
  y <- NoNA.xyz$y
  x <- NoNA.xyz$x
  z <- NoNA.xyz$z
  e <- NoNA.xyz$e
  q <- NoNA.xyz$q
  d <- NoNA.xyz$d
  
  mod <- lm(y ~ x + I(x^2) + e + d +z)
  sum_mod <- summary(mod)
  sum_mod
``` 
Model prediction
```{r}
  pred.y <- predict(mod)
  {plot(pred.y, y, main = paste0("8-day ", var, " Full Year"))
  abline(0,1)}
```
Model diagnostics
```{r}
  post_mod <- summary(lm(y ~ pred.y))
  gvmodel <- gvlma(mod)
  summary(gvmodel)
```
```{r}
  outlierTest(mod)
```

Assumptions:
```{r}
plot(mod)
```
```{r}
  spreadLevelPlot(mod)
```
```{r}
  plot(pred.y, mod$residuals, main="Model diagnostics Full Year", xlab="Predicted", ylab="Residuals")
```
```{r}
  pressstat_sum <- PRESS(mod, verbose = "FALSE")
  RMSEP <- sqrt(mean((pressstat_sum$residuals)^2))
  
  library(pls)
  mod2 <- plsr(y ~ x + I(x^2) + e + d + z, validation = "LOO")
  p2 <- R2(mod2)
  detach("package:pls", unload=TRUE)
  
  coeffs <- as.matrix(coefficients(sum_mod))
  
  pred.out <- matrix(nrow=length(pred.y), ncol=5)
  pred.out[,1] <- y
  pred.out[,2] <- pred.y
  pred.out[,3] <- z
  pred.out[,4] <- "full year"
  pred.out[,5] <- yearPath
  colnames(pred.out) <- c("Y", "PredY", "JulDay", "Season", "Year")
  write.table (x=pred.out,append=T,row.names=F,file=paste0("jk_pred_v_y_", var, "_", basin, "_", yearPath, "_full_year.csv"),sep = ",", col.names=F)  
  
```
```{r}  
  fit <- lm(y~ pred.y)
  
  summary(fit)
```
Output tables formatting for coeffs and metrics
```{r}    
  coeffs_out <- data.frame(Int=numeric(2), bLST=numeric(2), bLST2=numeric(2), bJul=numeric(2), bElev=numeric(2))
  metrics_out <- data.frame(r2=numeric(2), RMSE=numeric(2), p2=numeric(2), RMSEP=numeric(2), N_Sites=numeric(2), N=numeric(2))
  rownames(metrics_out) <- c("Spring", "Fall")
  rownames(coeffs_out) <- c("Spring", "Fall")
 # no Julday output 
  coeffs_out[1,1] <- coeffs[1,1]
  coeffs_out[1,2] <- coeffs[2,1] 
  coeffs_out[1,3] <- coeffs[3,1]
  coeffs_out[1,4] <- 0
  coeffs_out[1,5] <- coeffs[4,1]
  
  metrics_out[1,1] <- sum_mod$adj.r.squared
  metrics_out[1,2] <- sum_mod$sigma
  metrics_out[1,3] <- p2$val[5]
  metrics_out[1,4] <- RMSEP
  metrics_out[1,5] <- length(unique(NoNA.xyz$SiteName))
  metrics_out[1,6] <- length(y)
  
  coeffs_out[2,1] <- coeffs[1,1]
  coeffs_out[2,2] <- coeffs[2,1]
  coeffs_out[2,3] <- coeffs[3,1]
  coeffs_out[2,4] <- 0
  coeffs_out[2,5] <- coeffs[4,1]
  
  metrics_out[2,1] <- sum_mod$adj.r.squared
  metrics_out[2,2] <- post_mod$sigma
  metrics_out[2,3] <- p2$val[5]
  metrics_out[2,4] <- RMSEP
  metrics_out[2,5] <- length(unique(NoNA.xyz$SiteName))
  metrics_out[2,6] <- length(y)
  
  
  write.table(x=coeffs_out, append=F,row.names=T, file = paste0("All_data_", basin, "_", yearPath, "_mod_coeffs_", var, ".csv"), sep = ",", col.names=T)
  
  write.table(x=metrics_out, append=F,row.names=T, file = paste0("All_data_", basin, "_", yearPath, "_mod_metrics_", var, ".csv"), sep = ",", col.names=T)
  
```
####Spring/Fall models
Spring data model
```{r}
  coeffs_out <- data.frame(Int=numeric(2), bLST=numeric(2), bLST2=numeric(2), bJul=numeric(2), bElev=numeric(2), bD=numeric(2), bDJul=numeric(2))
  metrics_out <- data.frame(r2=numeric(2), RMSE=numeric(2), p2=numeric(2), RMSEP=numeric(2), N_Sites=numeric(2), N=numeric(2))
  rownames(metrics_out) <- c("Spring", "Fall")
  rownames(coeffs_out) <- c("Spring", "Fall")
```
```{r}
  y <- data.sp$y
  x <- data.sp$x
  z <- data.sp$z
  e <- data.sp$e
  d <- data.sp$d
  plot(x, y, main="Spring data")
```
```{r}
  mod <- lm(y ~ x+ I(x^2)+ z + e + d)
  sum_mod <- summary(mod)
  sum_mod
```
####Model diagnostics
```{r}
  pred.y <- predict(mod)
  pred.y[pred.y < -0.5] = -0.5
  {plot(pred.y, y, main = paste0("8-day ", var, " Spring Leg"))
  abline(0,1)}
```
Test assumption of linear model
```{r}
  post_mod <- summary(lm(y ~ pred.y))
  gvmodel <- gvlma(mod)
  summary(gvmodel)
```
check for outliers
```{r}
  outlierTest(mod)
```
more tests: qqplot
```{r}
  qqPlot(mod, main="QQ Plot Spring Leg")
```
format the data for prediction output 
```{r}
  
  coeffs <- as.matrix(coefficients(mod))
  pred.y <- predict(mod)
  
  pred.y[pred.y < -0.5] = -0.5
```
Look at the residuals
```{r}
  spreadLevelPlot(mod)
```
LOO PRESS stats
```{r, message=FALSE}
  pressstat_sum <- PRESS(sum_mod, verbose = "FALSE")
  RMSEP <- sqrt(mean((pressstat_sum$residuals)^2))
  
  library(pls)
  mod2 <- plsr(y ~ x + I(x^2) + z + e + d, validation = "LOO")
  p2 <- R2(mod2)
  detach("package:pls", unload=TRUE)
```
write out predicted, coeffs, & metrics
```{r}
  
  pred.out <- matrix(nrow=length(pred.y), ncol=5)
  pred.out[,1] <- y
  pred.out[,2] <- pred.y
  pred.out[,3] <- z
  pred.out[,4] <- "Spring"
  pred.out[,5] <- yearPath
  
  colnames(pred.out) <- c("Y", "PredY", "JulDay", "Season", "Year")
  write.table (x=pred.out,append=F,row.names=F,file=paste0("jk_pred_v_y_", var, "_", basin, "_", yearPath, "_sp_fall.csv"),sep = ",", col.names=F)  
  
  coeffs_out[1,1] <- coeffs[1,1]
  coeffs_out[1,2] <- coeffs[2,1]
  coeffs_out[1,3] <- coeffs[3,1]
  coeffs_out[1,4] <- coeffs[4,1]
  coeffs_out[1,5] <- coeffs[5,1]
  coeffs_out[1,6] <- coeffs[6,1]
  

  
  metrics_out[1,1] <- sum_mod$adj.r.squared
  metrics_out[1,2] <- sum_mod$sigma
  metrics_out[1,3] <- p2$val[5]
  metrics_out[1,4] <- RMSEP
  metrics_out[1,5] <- length(unique(data.sp$SiteName))
  metrics_out[1,6] <- length(y)
```
Fall data model
```{r}
  
  y <- data.fall$y
  x <- data.fall$x
  z <- data.fall$z 
  e <- data.fall$e
  d <- data.fall$d
  
  plot(x, y, main="fall")
```
```{r}
  mod <- lm(y ~ x + I(x^2) + z + e + d)
  sum_mod <- summary(mod)
  sum_mod
```
####Model Diagnostics
plot predicted v observed
```{r}
  pred.y <- predict(mod)
  pred.y[pred.y < -0.5] = -0.5
  {plot(pred.y, y, main = paste0("8-day ", var, " Fall Leg"))
  abline(0,1)}
```
Tests of assumptions of linear model
```{r}
  gvmodel <- gvlma(mod)
  summary(gvmodel)
```
check for outliers
```{r}
  outlierTest(mod)
```
plot model diagnostics
```{r}
  plot(mod)
```

more diagonstics: qqplot
```{r}
  qqPlot(mod, main="QQ Plot Fall Leg")
```

format data for prediction output
```{r}
  coeffs <- as.matrix(coefficients(mod))
  post_mod <- summary(lm(y ~ pred.y)) 
```
LOO PRESS stats
```{r, message=FALSE}
  pressstat_sum <- PRESS(sum_mod, verbose = "FALSE")
  RMSEP <- sqrt(mean((pressstat_sum$residuals)^2))
  
  library(pls)
  mod2 <- plsr(y ~ x + I(x^2) + z + e + d, validation = "LOO")
  p2 <- R2(mod2)
  detach("package:pls", unload=TRUE)
```
write out predicted, coeffs, & metrics
```{r}
  pred.out <- matrix(nrow=length(pred.y), ncol=5)
  pred.out[,1] <- y
  pred.out[,2] <- pred.y
  pred.out[,3] <- z
  pred.out[,4] <- "fall"
  pred.out[,5] <- yearPath
  
  write.table (x=pred.out,append=T,row.names=F,file=paste0("jk_pred_v_y_", var, "_", basin, "_", yearPath, "_sp_fall.csv"),sep = ",", col.names=F)  
  
  coeffs_out[2,1] <- coeffs[1,1]
  coeffs_out[2,2] <- coeffs[2,1]
  coeffs_out[2,3] <- coeffs[3,1]
  coeffs_out[2,4] <- coeffs[4,1]
  coeffs_out[2,5] <- coeffs[5,1]
  coeffs_out[2,6] <- coeffs[6,1]

  
  metrics_out[2,1] <- sum_mod$adj.r.squared
  metrics_out[2,2] <- post_mod$sigma
  metrics_out[2,3] <- p2$val[5]
  metrics_out[2,4] <- RMSEP
  metrics_out[2,5] <- length(unique(data.fall$SiteName))
  metrics_out[2,6] <- length(y)

  
  write.table(x=coeffs_out, append=F,row.names=T, file = paste0("All_data_", basin, "_", yearPath, "_mod_coeffs_", var, ".csv"), sep = ",", col.names=T)
  
  write.table(x=metrics_out, append=F,row.names=T, file = paste0("All_data_", basin, "_", yearPath, "_mod_metrics_", var, ".csv"), sep = ",", col.names=T)
  
```
plot the full year of predicted v observed
```{r}
  pred.y <- read.csv(paste0("jk_pred_v_y_", var, "_", basin, "_", yearPath, "_sp_fall.csv"), stringsAsFactors = FALSE, header = FALSE)
  colnames(pred.y) <- c("Y", "PredY", "JulDay", "Season", "Year")
  
  {plot(pred.y$PredY, pred.y$Y, pch=16, col="blue", main=paste0(var, " 8-day stream temp ", basin, " ", yearPath), xlab="Predicted", ylab="Observed")
  abline(0,1)
  abline(lm(pred.y$Y~ pred.y$PredY), col="blue")}
```
full year fit metrics
```{r}
  fit <- lm(pred.y$Y~ pred.y$PredY)
  
  summary(fit)
```
This part applies the model coefficients to the LST to generate 8-day temp estimates 
```{r}
  elev.in <- read.csv(paste0("D:/OneDrive/work/research/CHaMP/CHaMP_data/Alsea/AL_rca_elev.csv"), stringsAsFactors = F)
  
  LST.in <- read.dbf(paste0("D:/OneDrive/work/research/CHaMP/CHaMP_data/Alsea/2016/LST16_AL_RCA.dbf"))
  
  colnames(LST.in)<-gsub("X", "", colnames(LST.in))
  
  newnamesnum <- as.numeric(colnames(LST.in)[1:46])
  
  LST.elev <- merge(LST.in, elev.in, by = "RCAID")
  
  coeffs.in <- read.csv(paste0("All_data_", basin, "_", yearPath, "_mod_coeffs_", var, ".csv"), stringsAsFactors=FALSE)
  LogPred.out <- LST.elev[,c(2:47,48,1)]
  LogPred.out[,1:46] <- 0
  rcas <- unique(LST.elev$RCAID)
  LST.sum <- LST.elev[,c(2:47, 48,1)]
  

   for (i in 1:length(rcas))  
      {
        x <- unlist(LST.sum[i,])
        maxrow <- 29 #as.numeric(which.max(x[1:46]))
        midrow <- maxrow - 1
        day <- as.numeric(colnames(LST.sum)[maxrow])
        
        j <- 1
        for (l in 1:midrow)
        {x[l] <- x[l] * coeffs.in$bLST[1] + j * coeffs.in$bJul[1] +  x[47] * coeffs.in$bElev[1] + Dv[l] * coeffs.in$bD[1] + x[l]^2 * coeffs.in$bLST2[1] + j*Dv[l]*coeffs.in$bDJul[1] + coeffs.in$Int[1]
        j <- j + 8}
        k <- day
        for (l in maxrow:46)     
        {x[l] <- x[l] * coeffs.in$bLST[2] + k * coeffs.in$bJul[2] +  x[47] * coeffs.in$bElev[2] + Dv[l] * coeffs.in$bD[2] + x[l]^2 * coeffs.in$bLST2[2] + j*Dv[l]*coeffs.in$bDJul[2] + coeffs.in$Int[2]
        k <- k + 8}
        if (maxrow > 3)
        {
          x[(midrow)] <- NA
          fill <- na.spline(x[1:46],)
          x[(maxrow-3):(maxrow+3)] <- fill[(maxrow-3):(maxrow+3)]
        }
        LogPred.out[i,1:46] <- x [1:46] 
      }
    
  
  LogPred.out <- as.data.frame(LogPred.out)
  
  LogPred.out$Basin_RCA <- paste0(basin, "_", LogPred.out$RCAID)
  namesnum <- as.numeric(colnames(LogPred.out[1:46]))
  varName <- paste0("T", var, yrPath)
  names.out <- sprintf("%s_%03d", varName, namesnum)
  colnames(LogPred.out)[1:46] <- names.out[1:46]
  LogPred.out[LogPred.out < -0.5] = -0.5
  
  write.dbf(LogPred.out, file = paste0("predt", yearPath, "_", basin, "_8D_", var, ".dbf"))
```
Plot orig data
```{r}
  plot(NoNA.xyz$z, NoNA.xyz$y)
```
Plot some reaches to take a peek
```{r}  
  {plot(namesnum, LogPred.out[1,1:46])
  points(namesnum, LogPred.out[35, 1:46], pch=16, col="blue")
  points(namesnum, LogPred.out[1000, 1:46], pch=16, col="green")
  points(namesnum, LogPred.out[200, 1:46], pch=16, col="red")
  points(namesnum, LogPred.out[80, 1:46], pch=16, col="lightblue")}
  
```
This parts formats the error by day/site info

```{r}

  Log.in <- read.csv(paste0("D:/OneDrive/work/research/CHaMP/CHaMP_data/Alsea/2016/AL_logger_8D_2016.csv"), stringsAsFactors = FALSE)
  
  ID.in <- read.csv(paste0("D:/OneDrive/work/research/CHaMP/GIS/coverages/Alsea/AL_sites_rca_2016.csv"), stringsAsFactors = FALSE) 
  
  
  Pred.in <- read.dbf(paste0("predt", yearPath, "_", basin, "_8D_", var, ".dbf"))
  colnames(Pred.in)<-gsub(varName, "", colnames(Pred.in))
  colnames(Pred.in)<-gsub("_", "", colnames(Pred.in))
  newnamesnum <- as.numeric(colnames(Pred.in)[1:46]);
  
  Pred.Log.out <- data.frame (mup = NULL)
  SiteID <- unique(Log.in$SiteName)

    for (i in SiteID) 
      { 
        Log.site <- Log.in[Log.in$SiteName  == i,]
        Log.site <- as.data.frame(Log.site)
        
        
        RCAID <- ID.in$RCAID[ID.in$SiteName == i]
        
        Pred.site <- matrix(ncol=2, nrow=46)
        Pred.site[,1] <- as.numeric(unlist(colnames(Pred.in)[1:46]))
        Pred.site[,2] <- unlist(Pred.in[Pred.in$RCAID == RCAID,1:46])
        Pred.site <- data.frame(Pred.site)
        colnames(Pred.site) <- c("JulDay", "Pred")
        
        Pred.Log.site <- merge(Pred.site, Log.site, by.x = "JulDay",by.y = "JulDay", all.x=TRUE, all.y = FALSE)
        
        Pred.Log.out <- rbind(Pred.Log.out, Pred.Log.site)
      }

  ind <- apply(Pred.Log.out, 1, function(x) !any(is.na(x)))
  NoNA.pred <- Pred.Log.out[ind,]
  
  NoNA.pred <- NoNA.pred[,c(dataVar, "Pred", "JulDay", "SiteName")]
  colnames(NoNA.pred) <- c("Obs", "Pred", "JulDay", "SiteName")
  

  SiteID <- unique(NoNA.pred$SiteName)
  SiteID <- as.matrix(SiteID)
  Error.pts.out <- matrix(nrow = length(SiteID), ncol = 47)
  
  errorName <- paste0("JulDay_", namesnum)
  colnames(Error.pts.out)[2:47] <- errorName
  colnames(Error.pts.out)[1] <- "SiteName"
  
  Error.pts.out[1:length(SiteID), 1] <- unlist(SiteID)[1:length(SiteID)]
  Error.pts.out <- as.data.frame(Error.pts.out, stringsAsFactors = FALSE)


    for (i in SiteID) 
      { 
        error.site <- NoNA.pred[NoNA.pred$SiteName  == i,]
        error.site$error <- error.site[,'Obs']-error.site[,'Pred']
        
        
        error <- matrix(ncol=1, nrow=46)
        error[,1] <- namesnum
        error <- data.frame(error)
        colnames(error) <- c("JulDay")
        
        error.site.fill <- merge(error, error.site, by = "JulDay", all.x=TRUE, all.y = FALSE)
        Error.pts.out[Error.pts.out$SiteName==i,2:47] <- as.numeric(unlist(error.site.fill$error))
      }

  Error.pts.out[,2:47] <- sapply(Error.pts.out[,2:47], as.numeric)
  
  Error.pts.out[,2:47] <- round(Error.pts.out[,2:47], digits=3)

write.dbf(Error.pts.out, file = paste0("Error", yearPath, "_", basin, "_8D_", var, ".dbf")) 
write.csv(Error.pts.out, file = paste0("Error", yearPath, "_", basin, "_8D_", var, ".csv"), row.names = FALSE)
```
Geospatial data output
```{r}

  gisPath <- paste0("D:/OneDrive/work/research/CHaMP/GIS/coverages/", longBasin)
  
  netname <- paste0("Alsea_NSI_2016")
  ptsname <- paste0("AL_TempSite_2016")
  
  error_pts <- readOGR(dsn=gisPath, ptsname)
  error_pts@data <- error_pts@data[,c("SiteName", "RCAID")]
  
  network <- readOGR(dsn=gisPath, layer = netname)
  network@data <- network@data[,c("RCAID", "RCAID")]
  colnames(network@data)[1] <- "RCAID"
  
  network <- spTransform(network, proj4string(error_pts))
  
  error_pts <- merge(error_pts, Error.pts.out, by.x="SiteName", by.y="SiteName")
  network <- merge(network, LogPred.out, by = "RCAID")                    
                    
  outnetname <- paste0(basin, "_", yearPath, "_8D_", var)
  outptsname <- paste0(basin, "_Error_", yearPath, "_8D_", var)
  
  writeOGR(obj=error_pts, dsn=".", layer = paste0(outptsname), driver="ESRI Shapefile", overwrite_layer = TRUE)
  writeOGR(obj=network, dsn=".", layer = paste0(outnetname), driver="ESRI Shapefile", overwrite_layer = TRUE)
```
Animation output
```{r}

  seis = c("#480000","#5e0000","#770000","#910000", "#AA0000", "#D00000", "#F70000", "#FF1D00", "#FF4400", "#FF6A00", "#FF9000", "#FFB700", "#FFDD00", "#FFE200", "#BDFF0C", "#73FF1A", "#3FFA36", "#16F45A", "#00D08B", "#0087CD", "#0048FA", "#0024E3")
  seis <- rev(seis)

  network@data$RCAID <- as.numeric(network@data$RCAID)

  names.out <- colnames(network@data[3:48])
  namesnum <- as.numeric(gsub(paste0("T", var, yrPath, "_"), "", colnames(network@data[3:48])))
  means <- colMeans(network@data[3:48], na.rm = TRUE)
  SDs <- colStdevs(network@data[3:48], na.rm = TRUE)
  yplus <- means + SDs
  yminus <- means - SDs
  df <- data.frame(means=means, SDs=SDs, names=namesnum)
  sequ <- c(1:46)
  namer <- sprintf('%03d', sequ)
  fix4 <- classIntervals(means, n = 14, style = "fixed",fixedBreaks=c(-1,2,4,6,8,10,12,14,16,18,20,22,24,26))
  fix4.colors <- findColours(fix4,pal=seis)
```
loops through and writes out the graphics
```{r}

  for (i in 3:48)
    {
      
      namey <- gsub(paste0("T", var, yrPath, "_"), "", colnames(network@data)[i])
      
      filename <- paste0(modelPath, "graphics/", namer[i-2], ".png", sep="")
      png(filename=filename, res = 300, width = 1700, height = 1700, units = "px", bg="black")
      
      u <- unique(network@data[,i])
      
      if(length(u )< 3){ 
        fix3.colors <- rep("#0024E3",282)
      } else {
      fix3 <- classIntervals(network@data[,i], n = 15, style = "fixed",fixedBreaks=c(-1,2,4,6,8,10,12,14,16,18,20,22,24,26))
      fix3.colors <- findColours(fix3,pal=seis)
      }

      cexEr <-ifelse(abs(error_pts@data[,i]) == 0, 0,
                     ifelse(abs(error_pts@data[,i])>0 & error_pts@data[,i-1]<1, 0.5,
                            ifelse(abs(error_pts@data[,i])>1 & error_pts@data[,i-1]<2, 0.75,
                                   ifelse(abs(error_pts@data[,i])>2 & error_pts@data[,i]<3, 1.0,
                                          ifelse(abs(error_pts@data[,i])>3, 1.25,
                                                 ifelse(abs(error_pts@data[,i])== NA, 0, NA))))))
      
      plot(network, col=fix3.colors, bg="black", fg="white")
      points(error_pts, pch=16, col="gray40", cex=cexEr)
      
       legend(x=grconvertX(c(0.70,0.75), from='npc'), 
        y=grconvertY(c(0.55, 0.99), from='npc'), fill = c("#0024E3", "#0087CD", "#16F45A", "#3FFA36", "#BDFF0C", "#FFDD00", "#FF9000", "#FF4400", "#F70000", "#AA0000", "#910000","#770000","#5e0000", "#480000"), legend = c("0-2","2-4","4-6","6-8","8-10","10-12","12-14","14-16","16-18","18-20", "20-22","22-24","2-26","26"), bty = "n", cex=.5, inset=c(.1,0), text.col="white");
        
       legend("topright", pch=16, col="gray40", pt.cex=c(0.5, 0.75, 1.0, 1.25), title="Model error (°C)", legend = c("0-1","1-2","2-3","3+"), bty = "n", cex=.5, inset=c(0,0), text.col="white");
        
      
      
      title(paste0(nameBasin, " 8-day ", longVar, " ", yearPath, " (°C)"), line=-0.6, adj=0, col.main="white", col.sub="white", outer=FALSE, cex.main=0.5)
      mtext(paste0("Julian Day ", namey),side =1, outer=TRUE, line=-5, col="white", cex=.5)
      
      tmp2 <- subplot(
        plot(namesnum[1:(i-2)], means[1:(i-2)], col=fix4.colors, pch=16, bty="n", xlim=c(0,360), ylim=c(0,20), cex.main=.8, main="Basin mean (+/-SD)", adj=0, xlab='',ylab='', col.lab="white", cex.axis=0.5, cex.lab = 0.25, col.axis="white", col.main = "white", bg="black"), 
        x=grconvertX(c(0.65,0.99), from='npc'), 
        y=grconvertY(c(0.4, 0.55), from='npc'),
        size=c(1,1.5), vadj=0.5, hadj=0.5, 
        pars=list( mar=c(0,0,0,0)+0.1, cex=0.5))
      op <- par(no.readonly=TRUE)
      par(tmp2)
      arrows(namesnum[1:(i-2)], yplus[1:(i-2)], namesnum[1:(i-2)], yminus[1:(i-2)], length=0, lwd=5, code=3, lend=0, col="gray20")
      par(op)
      tmp2 <- subplot(
        plot(namesnum[1:(i-2)], means[1:(i-2)], col=fix4.colors, pch=16, bty="n", xlim=c(0,360), ylim=c(0,20), cex.main=.8, main="Basin mean (+/-SD)", adj=0, xlab='',ylab='', col.lab="white", cex.axis=0.5, cex.lab = 0.25, col.axis="white", col.main = "white", bg="black"), 
        x=grconvertX(c(0.65,.99), from='npc'), 
        y=grconvertY(c(0.4, 0.55), from='npc'),
        size=c(1,1.5), vadj=0.5, hadj=0.5, 
        pars=list( mar=c(0,0,0,0)+0.1, cex=0.5))
      
      dev.off()
    }
    
  
```
This system call builds an mpeg out of the still graphics
```{r, message=FALSE, warning=FALSE}
setwd(paste0(modelPath, "/graphics/"))
  
  system('"C:/Program Files/ImageMagick-7.0.1-Q16/convert.exe" -delay 20 -morph 3 *.png AL_2016_8D_Mn.mpeg')
```
Still graphic output for wiki or web or wev
```{r}
  i <- 24  
  namey <- gsub(paste0("T", var, "_", yrPath, "_"), "", colnames(network@data)[i])
  fix3 <- classIntervals(network@data[,i], n = 11, style = "fixed",fixedBreaks=c(-1,2,4,6,8,10,12,14,16,18, 20))
  fix3.colors <- findColours(fix3,pal=seis)
  
  filename <- paste0(modelPath, "/graphics/Stills/", basin, "_", yearPath, "_8D_", var, ".png", sep="")
    png(filename=filename, res = 300, width = 1500, height = 1500, units = "px", bg="white")
    
        cexEr <- ifelse(abs(error_pts@data[,i]) <= 1, 0.5,
                        ifelse(abs(error_pts@data[,i])>1, 0.75,
                               ifelse(abs(error_pts@data[,i])>2, 1.0,
                                      ifelse(abs(error_pts@data[,i])>3, 1.25, NA))))
        
        plot(network, col=fix3.colors, bg="white", fg="black")
        points(error_pts, pch=16, col="gray40", cex=cexEr)
        
        legend(x=grconvertX(c(0.85,0.9), from='npc'), 
        y=grconvertY(c(0.3, 0.55), from='npc'), 
        fill = attr(fix3.colors, "palette"), title=paste0("8-day ", var, " (°C)"),legend = c("0-6","6-8","8-10","10-12","12-14","14-16","16-18","18-20", "20-22", "22+"), bty = "n", cex=.5, inset=c(0,0), text.col="black");
        legend("bottomright", pch=16, col="gray40", pt.cex=c(0.5, 0.75, 1.0, 1.25), title="Model error (°C)", legend = c("0-1","1-2","2-3","3+"), bty = "n", cex=.5, inset=c(0,0), text.col="black");
        
        mtext(paste0(nameBasin, " ",  yearPath, " 8-day ", var, " (°C)"),side =3, outer=TRUE, line=-3, col="black", cex=.7)
        mtext(paste0("Julian Day ", namey),side =1, outer=TRUE, line=-3, col="black", cex=.7)
        
        tmp2 <- subplot(
          plot(namesnum[1:(i-2)], means[1:(i-2)], col=fix4.colors, pch=16, bty="n", xlim=c(0,360), ylim=c(0,22), cex.main=.8, main="Basin mean", adj=0, xlab='',ylab='', col.lab="black", cex.axis=0.5, cex.lab = 0.25, col.axis="black", col.main = "black", bg="white"), 
          x=grconvertX(c(0.01,0.40), from='npc'), 
          y=grconvertY(c(0.05, 0.20), from='npc'),
          size=c(1,1.5), vadj=0.5, hadj=0.5, 
          pars=list( mar=c(0,0,0,0)+0.1, cex=0.5))
```
This part generates the project.rs.xml file 
```{r, message=FALSE}

Realizguid = UUIDgenerate(F)

now <- Sys.Date()

```
Start writing project.rs.xml file here
```{r}

cat("", file=paste(modelPath,"project.rs.xml",sep=""))

cat(paste("","<?xml version=\"1.0\" encoding=\"utf-8\"?>
<Project xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"
  xsi:noNamespaceSchemaLocation=\"https://raw.githubusercontent.com/Riverscapes/Program/master/Project/XSD/V1/Project.xsd\">

  <Name>stream_temperature_project</Name>
  <ProjectType>STREAMTEMP",capVar,"</ProjectType>

  <MetaData>
    <!--This first metadata exists only to place this project in the riverscapes project-->
    <Meta name=\"HUCID\">17060201</Meta>
		<Meta name=\"Region\">CRB</Meta>
    <Meta name=\"Watershed\">",nameBasin,"</Meta>
     <Meta name=\"Year\">", yearPath,"</Meta>
  </MetaData>

  
  <Inputs>
  </Inputs>

  <Realizations>
    <StreamTemperature guid=\"",Realizguid,"\" id=\"streamtemp\" dateCreated=\"",now,"\" productVersion=\"1.0\">
      <Name>Stream Temperature for ",nameBasin, " ",yearPath,"</Name>

      <MetaData>
        <!--This next metadata relates to this particular realization-->
        <Meta name=\"MODIS_dataset\">MOD11A2v005</Meta>
        <Meta name=\"EOSDIS\">https://reverb.echo.nasa.gov/reverb/</Meta>
        <Meta name=\"Logger_data_source\">www.champmonitoring.org</Meta>
        <Meta name=\"Code_wiki\">https://github.com/SouthForkResearch/StreamTemperature/wiki</Meta>
      </MetaData>

      <Analyses>
        <Analysis>
          <Name>Stream Temp Analysis</Name>
          <Outputs>

            <CSV id=\"coeffs\">
              <Name>Model_coefficients</Name>
              <Path>All_data_",basin,"_",yearPath,"_mod_coeffs_",var,".csv</Path>
              <MetaData>
                <Meta name=\"description\">Parameter coefficients for the final model</Meta>
              </MetaData>
            </CSV>

            <CSV id=\"metrics\">
              <Name>Model_metrics</Name>
              <Path>All_data_",basin,"_",yearPath,"_mod_metrics_",var,".csv</Path>
              <MetaData>
                <Meta name=\"description\">Model quality metrics</Meta>
              </MetaData>
            </CSV>

            <CSV id=\"error\">
              <Name>Model_error</Name>
              <Path>Error_",basin,"_",yearPath,"_8D_",var,".csv</Path>
              <MetaData>
                <Meta name=\"description\">Model estimation error for each 8-day period by site</Meta>
              </MetaData>
            </CSV>

            <CSV id=\"estimates\">
              <Name>Model_data_prediction</Name>
              <Path>jk_pred_v_y_",var, "_", basin,"_",yearPath,"_sp_fall.csv</Path>
              <MetaData>
                <Meta name=\"description\">Jack-knifed temperature estimate for each 8-day logger input</Meta>
              </MetaData>
            </CSV>

            <CSV id=\"modelData\">
              <Name>Model_input_data</Name>
              <Path>", basin,"_",yearPath,"_8Day_",var,"_model_data.csv</Path>
              <MetaData>
                <Meta name=\"description\">Formatted input data used in the model</Meta>
              </MetaData>
            </CSV>
          
            <Image id=\"still\">
              <Name>Network_estimate_snapshot</Name>
              <Path>graphics/Stills/",basin,"_",yearPath,"_8D_",var,".png</Path>
              <MetaData>
                <Meta name=\"description\">Still image of estimated temperature and error-by-site on the network for one day</Meta>
              </MetaData>
            </Image>

            <Video id=\"movie\">
              <Name>Network_annual_estimate_animation</Name>
              <Path>graphics/",basin,"_",yearPath,"_8D_",var,".mpeg</Path>
            </Video>

            <Vector id=\"network\">
              <Name>Network_estimate_shapefile</Name>
              <Path>",basin,"_",yearPath,"_8D_",var,".shp</Path>
              <MetaData>
                <Meta name=\"description\">Shapefile of network with temperature estimates for each 8-day period</Meta>
              </MetaData>
            </Vector>

            <Vector id=\"errorPts\">
              <Name>Error_by_site_points</Name>
              <Path>",basin,"_Error_",yearPath,"_8D_",var,".shp</Path>
              <MetaData>
                <Meta name=\"description\">Point shapefile of all included sites with model estimation error</Meta>
              </MetaData>
            </Vector>

          </Outputs>
        </Analysis>
      </Analyses>
    </StreamTemperature>
  </Realizations>
</Project>
",sep=""), file=paste(modelPath,"project.rs.xml",sep=""), append=T)

```
